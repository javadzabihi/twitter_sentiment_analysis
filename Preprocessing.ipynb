{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = pd.read_csv('training.1600000.processed.noemoticon.csv', header=None,\n",
    "                           names=['sentiment','id','date','flag','user','text'], encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date      flag  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is no Neutral sentiment in the dataset.\n",
    "# There is no missing data for the sentiment column.\n",
    "twitter_data.sentiment.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is no missing data for the text column.\n",
    "twitter_data.text.isnull().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unnecessary columns from the dataset.\n",
    "twitter_data.drop(['id','date','flag','user'],axis=1,inplace=True)\n",
    "twitter_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Convert positive sentiments from 4 to 1\n",
    "twitter_data['sentiment'][twitter_data['sentiment']==4] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.sentiment.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>pre_clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  pre_clean_len\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...            115\n",
       "1          0  is upset that he can't update his Facebook by ...            111\n",
       "2          0  @Kenichan I dived many times for the ball. Man...             89\n",
       "3          0    my whole body feels itchy and like its on fire              47\n",
       "4          0  @nationwideclass no, it's not behaving at all....            111"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the length of tweets\n",
    "twitter_data['pre_clean_len'] = [len(t) for t in twitter_data.text]\n",
    "twitter_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum length of pre-cleaned tweet: 6\n"
     ]
    }
   ],
   "source": [
    "print('Minimum length of pre-cleaned tweet:', twitter_data.pre_clean_len.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of pre-cleaned tweet: 374\n"
     ]
    }
   ],
   "source": [
    "print('Maximum length of pre-cleaned tweet:', twitter_data.pre_clean_len.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a boxplot of tweet length\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plt.boxplot(twitter_data.pre_clean_len)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "token = WordPunctTokenizer()\n",
    "\n",
    "# Removing '@mention'\n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "# Removing URL links\n",
    "pat2 = r'https?://[^ ]+'\n",
    "# Combine patterns\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "# Removing URL links\n",
    "www_pat = r'www.[^ ]+'\n",
    "# Negation dictionary\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "# data cleaning function\n",
    "def tweet_cleaner(text):\n",
    "    # Remove HTML codes from text\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, '', souped)\n",
    "    stripped = re.sub(www_pat, '', stripped)\n",
    "    lower_case = stripped.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "    # During the letters_only process, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = [x for x  in token.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets = []\n",
    "for i in range(len(twitter_data)):\n",
    "    clean_tweets.append(tweet_cleaner(twitter_data['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awww that bummer you shoulda got david carr of third day to do it',\n",
       " 'is upset that he can not update his facebook by texting it and might cry as result school today also blah',\n",
       " 'dived many times for the ball managed to save the rest go out of bounds',\n",
       " 'my whole body feels itchy and like its on fire',\n",
       " 'no it not behaving at all mad why am here because can not see you all over there',\n",
       " 'not the whole crew',\n",
       " 'need hug',\n",
       " 'hey long time no see yes rains bit only bit lol fine thanks how you',\n",
       " 'nope they did not have it',\n",
       " 'que me muera']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that bummer you shoulda got david carr of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can not update his facebook b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dived many times for the ball managed to save ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it not behaving at all mad why am here beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that bummer you shoulda got david carr of...       0\n",
       "1  is upset that he can not update his facebook b...       0\n",
       "2  dived many times for the ball managed to save ...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it not behaving at all mad why am here beca...       0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe with cleaned tweets\n",
    "clean_data = pd.DataFrame(clean_tweets,columns=['text'])\n",
    "clean_data['target'] = twitter_data.sentiment\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that bummer you shoulda got david carr of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can not update his facebook b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dived many times for the ball managed to save ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it not behaving at all mad why am here beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that bummer you shoulda got david carr of...       0\n",
       "1  is upset that he can not update his facebook b...       0\n",
       "2  dived many times for the ball managed to save ...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it not behaving at all mad why am here beca...       0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the dataframe\n",
    "clean_data.to_csv('clean_tweets.csv',encoding='utf-8')\n",
    "# Load the clean dataset\n",
    "twitter_data = pd.read_csv('clean_tweets.csv',index_col=0)\n",
    "twitter_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 2 columns):\n",
      "text      1596041 non-null object\n",
      "target    1600000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 36.6+ MB\n"
     ]
    }
   ],
   "source": [
    "twitter_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text       True\n",
       "target    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are null cells for text column\n",
    "twitter_data.isnull().any(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text  target\n",
       "208  NaN       0\n",
       "249  NaN       0\n",
       "282  NaN       0\n",
       "398  NaN       0\n",
       "430  NaN       0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which cells are null in text column\n",
    "twitter_data[twitter_data.isnull().any(axis=1)].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3959"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of null cells\n",
    "np.sum(twitter_data.isnull().any(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0</td>\n",
       "      <td>1467863072</td>\n",
       "      <td>Mon Apr 06 22:33:25 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Artiel87</td>\n",
       "      <td>@mandayyy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>1467874569</td>\n",
       "      <td>Mon Apr 06 22:36:27 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Artiel87</td>\n",
       "      <td>@mandayyy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>1467881474</td>\n",
       "      <td>Mon Apr 06 22:38:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>__Susan__</td>\n",
       "      <td>@ITS_NEMESIS -------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>1467912842</td>\n",
       "      <td>Mon Apr 06 22:46:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KimberlyKane</td>\n",
       "      <td>@danadearmond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0</td>\n",
       "      <td>1467919452</td>\n",
       "      <td>Mon Apr 06 22:48:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jtmal0723</td>\n",
       "      <td>@anistorm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0           1                             2         3             4  \\\n",
       "208  0  1467863072  Mon Apr 06 22:33:25 PDT 2009  NO_QUERY      Artiel87   \n",
       "249  0  1467874569  Mon Apr 06 22:36:27 PDT 2009  NO_QUERY      Artiel87   \n",
       "282  0  1467881474  Mon Apr 06 22:38:20 PDT 2009  NO_QUERY     __Susan__   \n",
       "398  0  1467912842  Mon Apr 06 22:46:53 PDT 2009  NO_QUERY  KimberlyKane   \n",
       "430  0  1467919452  Mon Apr 06 22:48:48 PDT 2009  NO_QUERY     jtmal0723   \n",
       "\n",
       "                         5  \n",
       "208             @mandayyy   \n",
       "249           @mandayyy     \n",
       "282  @ITS_NEMESIS -------   \n",
       "398         @danadearmond   \n",
       "430             @anistorm   "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the original dataset\n",
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\",header=None, encoding='latin_1')\n",
    "# See the original content of null cells before cleaning process\n",
    "df.iloc[twitter_data[twitter_data.isnull().any(axis=1)].index,:].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1596041 entries, 0 to 1596040\n",
      "Data columns (total 2 columns):\n",
      "text      1596041 non-null object\n",
      "target    1596041 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Remove rows which contain null values\n",
    "twitter_data.dropna(inplace=True)\n",
    "twitter_data.reset_index(drop=True,inplace=True)\n",
    "twitter_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "twitter_data.to_csv('clean_tweeter_data.csv',encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_x = pd.concat([X_train, X_val, X_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec expects a list of lists.\n",
    "# Using punkt tokenizer for better splitting of a paragraph into sentences.\n",
    "import nltk.data\n",
    "#nltk.download('popular')\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_wordlist(review, remove_stopwords=False):\n",
    "    \n",
    "    # Converting to lower case and splitting\n",
    "    words = review.lower().split()\n",
    "    # Optionally remove stopwords\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))     \n",
    "        words = [w for w in words if not w in stops]\n",
    "    \n",
    "    return(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function splits a review into sentences\n",
    "def review_sentences(review, tokenizer, remove_stopwords=False):\n",
    "    # 1. Using nltk tokenizer\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = []\n",
    "    # 2. Loop for each sentence\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence)>0:\n",
    "            sentences.append(review_wordlist(raw_sentence, remove_stopwords))\n",
    "\n",
    "    # This returns the list of lists\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = []\n",
    "\n",
    "for review in X_train:\n",
    "    train_sentences += review_sentences(review, tokenizer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "w2v_model = word2vec.Word2Vec(train_sentences,\n",
    "                          workers = 4, # Number of parallel threads\n",
    "                          size = 300, # Word vector dimensionality\n",
    "                          min_count= 2, # Minimum word count\n",
    "                          window= 10, # Context window size\n",
    "                          sample= 1e-3) # Downsample setting for frequent words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kitchen'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Few tests: This will print the odd word among them \n",
    "w2v_model.wv.doesnt_match(\"man woman dog child kitchen\".split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('guy', 0.5257232785224915),\n",
       " ('dude', 0.5217115879058838),\n",
       " ('boy', 0.497385174036026),\n",
       " ('woman', 0.46953463554382324),\n",
       " ('balls', 0.42327579855918884),\n",
       " ('kid', 0.41947418451309204),\n",
       " ('shit', 0.41885673999786377),\n",
       " ('fella', 0.4185824394226074),\n",
       " ('nigga', 0.41829344630241394),\n",
       " ('men', 0.4113842248916626)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will print the most similar words present in the model\n",
    "w2v_model.wv.most_similar(\"man\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.7727991342544556),\n",
       " ('horrible', 0.7621821165084839),\n",
       " ('horrid', 0.6376410722732544),\n",
       " ('aweful', 0.6323171854019165),\n",
       " ('miserable', 0.6223897337913513),\n",
       " ('icky', 0.5958918929100037),\n",
       " ('disgusting', 0.5871309638023376),\n",
       " ('dreadful', 0.5814915895462036),\n",
       " ('rubbish', 0.5657370686531067),\n",
       " ('unpleasant', 0.5648154020309448)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(\"awful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(105040, 300)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will give the total number of words in the vocabolary created from this dataset\n",
    "w2v_model.wv.syn0.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to average all word vectors in a paragraph\n",
    "def featureVecMethod(words, model, num_features):\n",
    "    # Pre-initialising empty numpy array for speed\n",
    "    featureVec = np.zeros(num_features,dtype=\"float32\")\n",
    "    nwords = 0\n",
    "    \n",
    "    #Converting Index2Word which is a list to a set for better speed in the execution.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in  words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    \n",
    "    # Dividing the result by number of words to get average\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating the average feature vector\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    counter = 0\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    for review in reviews:\n",
    "        # Printing a status message every 10000th review\n",
    "        if counter%100000 == 0:\n",
    "            print(\"Review %d of %d\"%(counter,len(reviews)))\n",
    "            \n",
    "        reviewFeatureVecs[counter] = featureVecMethod(review, model, num_features)\n",
    "        counter = counter+1\n",
    "        \n",
    "    return reviewFeatureVecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 1564120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  del sys.path[0]\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 100000 of 1564120\n",
      "Review 200000 of 1564120\n",
      "Review 300000 of 1564120\n",
      "Review 400000 of 1564120\n",
      "Review 500000 of 1564120\n",
      "Review 600000 of 1564120\n",
      "Review 700000 of 1564120\n",
      "Review 800000 of 1564120\n",
      "Review 900000 of 1564120\n",
      "Review 1000000 of 1564120\n",
      "Review 1100000 of 1564120\n",
      "Review 1200000 of 1564120\n",
      "Review 1300000 of 1564120\n",
      "Review 1400000 of 1564120\n",
      "Review 1500000 of 1564120\n"
     ]
    }
   ],
   "source": [
    "# Calculating average feature vector for training set\n",
    "clean_train_reviews = []\n",
    "for review in X_train:\n",
    "    clean_train_reviews.append(review_wordlist(review, remove_stopwords=False))\n",
    "    \n",
    "trainDataVecs = getAvgFeatureVecs(clean_train_reviews, w2v_model, num_features = 300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
